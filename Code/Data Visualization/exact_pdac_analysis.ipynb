{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e61a7a",
   "metadata": {},
   "source": [
    "# PDAC ILP (Exact) Algorithm analysis\n",
    "This notebook is used to analyze the performance of the ILP (exact) job scheduling algorithm. Specifically, it uses an relaxed ILP (inexact) scheduling algorithm, greedy heuristic scheduling algorithm and a naive scheduling algorithm for comparison. The peak demand above the curve (PDAC) is measured across five different trials for each specified job batch size and then plotted on a graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b34cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Add the parent directory of AAC/ to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed90b14",
   "metadata": {},
   "source": [
    "Import the ILP (exact), relaxed ILP (inexact), greedy and naive algorithms from their respective files in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d65342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PDAC.pdac_scheduling_ilp import solve_pdac_ilp\n",
    "from PDAC.pdac_scheduling_lp import solve_pdac_lp\n",
    "from PDAC.pdac_scheduling_greedy import solve_pdac_greedy\n",
    "from PDAC.pdac_scheduling_naive import solve_pdac_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9eec6f",
   "metadata": {},
   "source": [
    "# Program Parameters\n",
    "In the code below, you can specify the start time, end time and maximum length of each job in each batch of jobs. \\\n",
    "\\\n",
    "&emsp;&emsp; - 0 denotes 12am and 1400 denotes 12am of the following day. \\\n",
    "&emsp;&emsp; - Therefore, one day contains exactly 1440 minutes of job data\n",
    "\\\n",
    "\\\n",
    "Additionally, you can specify the sizes of each job batch that is analyzed in this program. \\\n",
    "\\\n",
    "&emsp;&emsp; - The start size is the smallest batch size to be analyzed \\\n",
    "&emsp;&emsp; - The end size is the largest batch size (exclusive) to be analyzed \\\n",
    "&emsp;&emsp; - The step size is how much the job batch increases per analytical trial\n",
    "\\\n",
    "\\\n",
    "For the exact algorithm, because it is an ILP, runtime increases exponentially as the job batch sizes increase. It is therefore advisable to keep the job batch sizes at or below 100 for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2d4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 0\n",
    "end_time = 1400\n",
    "max_length = 700\n",
    "\n",
    "start_size = 10\n",
    "end_size = 100\n",
    "step_size = 10\n",
    "\n",
    "analysis_num = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6913aee",
   "metadata": {},
   "source": [
    "# Resource Curve\n",
    "The resource curve is represented by a list of values across the specified time period. Where at a given time t there will be exactly resources[t] amount of power available to the jobs. The data for these resources is available in the Input_Data folder. \n",
    "\\\n",
    "\\\n",
    "Additionally, each height is multiplied by a scaling factor. This is so that the resource curve better fits the job curve. Otherwise, the resource curve would be too large for any sort of significant analysis. This scaling factor remains constant for each of the trials and for every job batch size for the sake of consistency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the resource curve\n",
    "path = \"../../Input_Data/resource_data.json\"\n",
    "with open(path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "wind_energy = data['series'][1]['data']\n",
    "solar_energy = data['series'][2]['data']\n",
    "hydro_energy = data['series'][3]['data']\n",
    "\n",
    "# Have 165 hours and you want minute by minute resolution. Therefore the total length of this list needs to be 165 * 60 in length\n",
    "# The first 60 values of the list need to equal 0, the next need to equal 1. Therefore, i // 60\n",
    "wind_energy_7_days = [0 for _ in range(165 * 60)]\n",
    "for i in range(len(wind_energy_7_days)):\n",
    "    wind_energy_7_days[i] = wind_energy[ i // 60 ]['value']\n",
    "\n",
    "solar_energy_7_days = [0 for _ in range(165 * 60)]\n",
    "for i in range(len(solar_energy_7_days)):\n",
    "    solar_energy_7_days[i] = solar_energy[ i // 60 ]['value']\n",
    "\n",
    "hydro_energy_7_days = [0 for _ in range(165 * 60)]\n",
    "for i in range(len(hydro_energy_7_days)):\n",
    "    hydro_energy_7_days[i] = hydro_energy[ i // 60 ]['value']\n",
    "\n",
    "\n",
    "total = []\n",
    "for i in range(165 * 60):\n",
    "    total_sum = wind_energy_7_days[i] + solar_energy_7_days[i] + hydro_energy_7_days[i]\n",
    "    total.append(total_sum)\n",
    "\n",
    "day = 3\n",
    "resources = total[(24 * day) + start_time : (24 * day) + end_time]\n",
    "\n",
    "# # Implement a resource curve scaling factor to better fit the jobs\n",
    "scale_factor = 0.05\n",
    "resources = [r * scale_factor for r in resources]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3525e5fa",
   "metadata": {},
   "source": [
    "# Algorithm Analysis\n",
    "For each batch size, there will be five trials run on each algorithm. Each time, a random assortment of jobs will be provided to the algorithms. However, these jobs will be the same for each algorithm, so they will be tested on the same jobs. This is for the most accurate possible comparisons. \n",
    "\\\n",
    "\\\n",
    "Additionally, the time it takes for each algorihtm to run is measured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is The list of job objects that will be scheduled\n",
    "# They each have a release, deadline, duration and height\n",
    "path = \"../../Input_Data/job_data.json\"\n",
    "with open(path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Randomly shuffle the jobs so that there is variation between trials\n",
    "jobs_array = data['jobs']\n",
    "\n",
    "pdac_inexact = []\n",
    "pdac_exact = []\n",
    "pdac_greedy = []\n",
    "pdac_naive = []\n",
    "\n",
    "final_data = []\n",
    "\n",
    "for batch_size in range(start_size, end_size, step_size):\n",
    "    exact_total = 0\n",
    "    inexact_total = 0\n",
    "    greedy_total = 0\n",
    "    naive_total = 0\n",
    "    \n",
    "    print(f\"\\nBatch Size: {batch_size}\")\n",
    "\n",
    "    for trial in range(5):\n",
    "        print(f\"Trial #: {trial}\")\n",
    "        random.shuffle(jobs_array)\n",
    "        \n",
    "        start = time.time()\n",
    "        exact = solve_pdac_ilp(jobs_array, resources, start_time, end_time, max_length, batch_size)[0]\n",
    "        exact_total += exact\n",
    "        end = time.time()\n",
    "        exact_time = end - start\n",
    "        print(f\"Exact Objective: {exact}, Elapsed Time: {exact_time}\")\n",
    "\n",
    "        start = time.time()\n",
    "        inexact = solve_pdac_lp(jobs_array, resources, start_time, end_time, max_length, batch_size)[0]\n",
    "        inexact_total += inexact\n",
    "        end = time.time()\n",
    "        inexact_time = end - start\n",
    "        print(f\"Inexact Objective: {inexact}, Elapsed Time: {inexact_time}\")\n",
    "\n",
    "        start = time.time()\n",
    "        greedy = solve_pdac_greedy(jobs_array, resources, start_time, end_time, max_length, batch_size)[0]\n",
    "        greedy_total += greedy\n",
    "        end = time.time()\n",
    "        greedy_time = end - start\n",
    "        print(f\"Greedy Objective: {greedy}, Elapsed Time: {greedy_time}\")\n",
    "\n",
    "        start = time.time()\n",
    "        naive = solve_pdac_naive(jobs_array, resources, start_time, end_time, max_length, batch_size)[0]\n",
    "        naive_total += naive\n",
    "        end = time.time()\n",
    "        naive_time = end - start\n",
    "        print(f\"Naive Objective: {naive}, Elapsed Time: {naive_time}\")\n",
    "\n",
    "        trial_data = {\n",
    "            \"batch size\": batch_size, \n",
    "            \"trial #\": trial,\n",
    "            \"exact objective val\": exact, \n",
    "            \"exact time\": exact_time, \n",
    "            \"naive obective val\": naive, \n",
    "            \"naive time\": naive_time, \n",
    "            \"inexact objective val\": inexact, \n",
    "            \"inexact time\": inexact_time, \n",
    "            \"greedy objective val\": greedy, \n",
    "            \"greedy time\": greedy_time\n",
    "        }\n",
    "        final_data.append(trial_data)\n",
    "\n",
    "    pdac_inexact.append(inexact_total / 5)\n",
    "    pdac_exact.append(exact_total / 5)\n",
    "    pdac_greedy.append(greedy_total / 5)\n",
    "    pdac_naive.append(naive_total / 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "inexact_list = [x / 1000 for x in pdac_inexact]\n",
    "\n",
    "greedy_list = [x / 1000 for x in pdac_greedy]\n",
    "\n",
    "naive_list = [x / 1000 for x in pdac_naive]\n",
    "\n",
    "exact_list = [x / 1000 for x in pdac_exact]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ced19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "# Plot data\n",
    "job_graph_xvalues = [i for i in range(start_size, end_size, step_size)]\n",
    "ax.plot(job_graph_xvalues, inexact_list, label=\"PDAC Inexact\", linestyle='-', color = 'black', linewidth=1.5)\n",
    "ax.plot(job_graph_xvalues, greedy_list, label=\"PDAC Greedy\", linestyle='--', color = 'black', linewidth=1.5)\n",
    "ax.plot(job_graph_xvalues, naive_list, label=\"PDAC Naive\", linestyle=':', color = 'black', linewidth=1.5)\n",
    "ax.plot(job_graph_xvalues, exact_list, label=\"PDAC Exact\", linestyle='-.', color = 'black', linewidth=1.5)\n",
    "\n",
    "ax.grid(True, linestyle='--', linewidth=0.25, color='black')\n",
    "plt.tick_params(axis='both', labelsize=14)\n",
    "ax.set_xticks(np.arange(start_size, end_size, step_size))  \n",
    "ax.set_yticks(np.arange(0, max(naive_list)+2, 2))\n",
    "\n",
    "ax.set_title(\"Algorithm Comparison by Batch Size\", fontsize=36, fontname=\"Georgia\", color='black')\n",
    "ax.set_xlabel(\"Job Batch Size\", fontsize=24, fontname='Verdana', color='black')\n",
    "ax.set_ylabel(\"Peak Demand Above \\n Curve (kWh)\", fontsize=24, fontname='Verdana', color='black')\n",
    "ax.legend(loc='upper left', prop={'family': 'Verdana', 'size': 14})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "# Set figure (outside) background\n",
    "fig.patch.set_facecolor(\"#261c15\")\n",
    "\n",
    "# Set axes (plot area) background\n",
    "ax.set_facecolor(\"#c2c2c2\")\n",
    "\n",
    "# Plot data\n",
    "job_graph_xvalues = [i for i in range(start_size, end_size, step_size)]\n",
    "ax.plot(job_graph_xvalues, inexact_list, label=\"PDAC Inexact\", linestyle='-', color = '#f77f00', linewidth=2.5)\n",
    "ax.plot(job_graph_xvalues, greedy_list, label=\"PDAC Greedy\", linestyle='--', color = '#0081a7', linewidth=2.5)\n",
    "ax.plot(job_graph_xvalues, naive_list, label=\"PDAC Naive\", linestyle=':', color = '#9448bc', linewidth=2.5)\n",
    "ax.plot(job_graph_xvalues, exact_list, label=\"PDAC Exact\", linestyle='-.', color = '#564e58', linewidth=2.5)\n",
    "\n",
    "ax.grid(True, linestyle='--', linewidth=0.25, color='black')\n",
    "plt.tick_params(axis='both', labelsize=14)\n",
    "ax.set_xticks(np.arange(start_size, end_size, step_size))\n",
    "ax.set_yticks(np.arange(0, max(naive_list)+2, 2))\n",
    "\n",
    "ax.set_title(\"Algorithm Comparison by Batch Size\", fontsize=36, fontname=\"Georgia\", color='white')\n",
    "ax.set_xlabel(\"Job Batch Size\", fontsize=24, fontname='Verdana', color='white')\n",
    "ax.set_ylabel(\"Peak Demand Above \\n Curve (kWh)\", fontsize=24, fontname='Verdana', color='white')\n",
    "ax.legend(loc='upper left', prop={'family': 'Verdana', 'size': 14})\n",
    "\n",
    "ax.tick_params(colors='white')\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor('white')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_data)\n",
    "job_graph_xvalues = np.array([i for i in range(start_size, end_size, step_size)])\n",
    "\n",
    "plt.plot(job_graph_xvalues, exact_list, label=\"PDAC Exact\", color='blue')\n",
    "plt.plot(job_graph_xvalues, inexact_list, label=\"PDAC Inexact\", color='orange')\n",
    "plt.plot(job_graph_xvalues, greedy_list, label=\"PDAC Greedy\", color='green')\n",
    "plt.plot(job_graph_xvalues, naive_list, label=\"PDAC Naive\", color='red')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Job Batch Size\")\n",
    "plt.ylabel(\"Power Demand Above Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "folder_path = r\"C:\\Users\\moaxs\\Desktop\\REU 2025\\PDM Project\\Code\\Graphs\\Comparison\\Output_Data\\PDAC_Results\"\n",
    "# Write to a data csv file\n",
    "with open(f\"{folder_path}/exact_pdac_analysis_{analysis_num}.csv\", \"a\", newline=\"\") as csvfile:\n",
    "    fieldnames = ['batch size', 'trial #', 'exact objective val', 'exact time', 'naive obective val', 'naive time', 'inexact objective val', 'inexact time', 'greedy objective val', 'greedy time']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    # Only write the header on the very first trial run\n",
    "    writer.writeheader()\n",
    "    writer.writerows(final_data)\n",
    "\n",
    "    csvfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cplex-new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
